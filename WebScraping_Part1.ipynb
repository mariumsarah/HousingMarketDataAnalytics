{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdd0ced5",
   "metadata": {},
   "source": [
    "# Notebook Organization\n",
    "\n",
    "## 1. [City Overview - Data Collection](#CityCountyLevel)\n",
    "\n",
    "## 2. [Home Level - Data Collection](#HomeLevel)\n",
    "\n",
    "## 3. [City Level - Data Collection](#CityLevel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60be4dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.request \n",
    "import urllib.parse\n",
    "import urllib.error\n",
    "import ssl\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from urllib.request import urlopen,Request\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.remote import webelement\n",
    "import pandas as pd\n",
    "import time\n",
    "# Selenium\n",
    "# Make sure to !pip install selenium\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "# For ignoring SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8484d3",
   "metadata": {},
   "source": [
    "# <a id=CityCountyLevel>1. City Overview - Data Collection </a> \n",
    "\n",
    "### In this section we access various pages within this page: to get the total homes available for rent in each city\n",
    "### Main Page used: 'https://www.redfin.com/rental-sitemap/CA'\n",
    "#### This section utilizes two different methods - \n",
    "#### (One) using beautiful soup and (second) using Selenium \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f506bbd",
   "metadata": {},
   "source": [
    "## Step 1: Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b90ac72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-b1e13c2f2238>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('chromedriver.exe')\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')\n",
    "#driver.get('https://www.redfin.com/city/17519/CA/San-Ramon/housing-market#agent-insights')\n",
    "\n",
    "#search_box = driver.find_element('searchInputBox')\n",
    "# search_box.send_keys('687 Catalina Laguna Beach, CA 92651')\n",
    "# search_box.submit()\n",
    "# time.sleep(3)\n",
    "# soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "# data = soup.find_all(lambda tag: tag.name == 'span' and tag.get('class') == ['value'])\n",
    "# print(data)\n",
    "\n",
    "driver.get('https://www.redfin.com/rental-sitemap/CA')\n",
    "elementcss= driver.find_element(By.XPATH,\"//ul[@class='list ldpsSection']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7a06914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   City Name  Total Homes for Rent  \\\n",
      "29     Corona                   38   \n",
      "30     Dublin                   19   \n",
      "31    Fremont                   84   \n",
      "32  Fullerton                   24   \n",
      "33     Irvine                  106   \n",
      "\n",
      "                                            City Link  \n",
      "29  https://www.redfin.com/city/4249/CA/Corona/apa...  \n",
      "30  https://www.redfin.com/city/5159/CA/Dublin/apa...  \n",
      "31  https://www.redfin.com/city/6671/CA/Fremont/ap...  \n",
      "32  https://www.redfin.com/city/7158/CA/Fullerton/...  \n",
      "33  https://www.redfin.com/city/9361/CA/Irvine/apa...  \n",
      "Processing Time:  92.0613260269165\n"
     ]
    }
   ],
   "source": [
    "# Check how long it takes\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "final_df_cities = pd.DataFrame( columns =['City Name ','Total Homes for Rent','City Link'])\n",
    "\n",
    "text = \"homes for rent in California\"\n",
    "cities = False\n",
    "city_web_elements = []\n",
    "elementListLength =len(driver.find_elements(By.TAG_NAME,\"a\"))\n",
    "wait = WebDriverWait(driver, 1)\n",
    "\n",
    "pattern = re.compile(r\"\")\n",
    "for x in range(elementListLength):\n",
    "    elementsList = driver.find_elements(By.TAG_NAME,\"a\")\n",
    "    if cities == False:\n",
    "        if elementsList[x].text == text:\n",
    "            cities = True\n",
    "    else:\n",
    "        if \"County\" in elementsList[x].text: \n",
    "            break\n",
    "        else:\n",
    "            city_name = elementsList[x].text\n",
    "            city_href = elementsList[x].get_attribute('href')\n",
    "            elementsList[x].click()\n",
    "            element = driver.find_element(By.XPATH,\"//div[@class='homes summary']\")\n",
    "            city_homes = int((re.findall('\\d+',element.text)[-1]))\n",
    "            # Insert into dataframe\n",
    "            final_df_cities.loc[x] = [city_name,city_homes,city_href]\n",
    "            driver.back()\n",
    "            \n",
    "print(final_df_cities) \n",
    "\n",
    "end = time.time()\n",
    "print('Processing Time: ',end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c2defd",
   "metadata": {},
   "source": [
    "## Step 2: Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b944cbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          City Name  Total Homes for Rent  \\\n",
      "0             Corona                   38   \n",
      "1             Dublin                   19   \n",
      "2            Fremont                   84   \n",
      "3          Fullerton                   24   \n",
      "4             Irvine                  106   \n",
      "5          Livermore                   14   \n",
      "6         Long Beach                  363   \n",
      "7        Los Angeles                 2272   \n",
      "8            Oakland                  512   \n",
      "9       Palm Springs                   90   \n",
      "10          Pasadena                   81   \n",
      "11        Pleasanton                   18   \n",
      "12  Rancho Cucamonga                   30   \n",
      "13         Riverside                   80   \n",
      "14        Sacramento                  409   \n",
      "15         San Diego                  661   \n",
      "16     San Francisco                  899   \n",
      "17          San Jose                  335   \n",
      "18         San Ramon                   22   \n",
      "19          Temecula                   29   \n",
      "\n",
      "                                            City Link  \n",
      "0   https://www.redfin.com/city/4249/CA/Corona/apa...  \n",
      "1   https://www.redfin.com/city/5159/CA/Dublin/apa...  \n",
      "2   https://www.redfin.com/city/6671/CA/Fremont/ap...  \n",
      "3   https://www.redfin.com/city/7158/CA/Fullerton/...  \n",
      "4   https://www.redfin.com/city/9361/CA/Irvine/apa...  \n",
      "5   https://www.redfin.com/city/10683/CA/Livermore...  \n",
      "6   https://www.redfin.com/city/10940/CA/Long-Beac...  \n",
      "7   https://www.redfin.com/city/11203/CA/Los-Angel...  \n",
      "8   https://www.redfin.com/city/13654/CA/Oakland/a...  \n",
      "9   https://www.redfin.com/city/14315/CA/Palm-Spri...  \n",
      "10  https://www.redfin.com/city/14498/CA/Pasadena/...  \n",
      "11  https://www.redfin.com/city/14986/CA/Pleasanto...  \n",
      "12  https://www.redfin.com/city/15390/CA/Rancho-Cu...  \n",
      "13  https://www.redfin.com/city/15935/CA/Riverside...  \n",
      "14  https://www.redfin.com/city/16409/CA/Sacrament...  \n",
      "15  https://www.redfin.com/city/16904/CA/San-Diego...  \n",
      "16  https://www.redfin.com/city/17151/CA/San-Franc...  \n",
      "17  https://www.redfin.com/city/17420/CA/San-Jose/...  \n",
      "18  https://www.redfin.com/city/17519/CA/San-Ramon...  \n",
      "19  https://www.redfin.com/city/19701/CA/Temecula/...  \n",
      "Processing Time:  26.27956199645996\n"
     ]
    }
   ],
   "source": [
    "# Check how long it takes\n",
    "start_bs = time.time()\n",
    "\n",
    "webpage = urlopen(Request('https://www.redfin.com/rental-sitemap/CA', headers={'User-Agent': 'Mozilla/5.0'}))\n",
    "soup = BS(webpage,'html.parser')\n",
    "    \n",
    "final_df_cities_bs = pd.DataFrame( columns =['City Name ','Total Homes for Rent','City Link'])\n",
    "\n",
    "text = \"homes for rent in California\"\n",
    "cities = False\n",
    "counter = 0 \n",
    "for x in soup.find_all('a'):\n",
    "    if cities == False:\n",
    "        if x.get_text() == text:\n",
    "             cities = True\n",
    "    else:\n",
    "        if \"County\" in x.get_text(): \n",
    "            break\n",
    "        else:\n",
    "            \n",
    "            city_name = x.get_text()\n",
    "            city_href = 'https://www.redfin.com'+x['href']\n",
    "            webpage2 = urlopen(Request(city_href, headers={'User-Agent': 'Mozilla/5.0'}))\n",
    "            soup2 = BS(webpage2,'html.parser')\n",
    "            total_homes = (int((re.findall('\\d+',soup2.find_all(\"div\", {\"class\": \"homes summary\"})[0].get_text())[-1])))\n",
    "#             wait.until(EC.element_to_be_clickable(elementsList[x])).click()\n",
    "#             element = driver.find_element(By.XPATH,\"//div[@class='homes summary']\")\n",
    "#             city_homes = int((re.findall('\\d+',element.text)[-1]))\n",
    "            # Insert into dataframe\n",
    "            final_df_cities_bs.loc[counter] = [city_name,total_homes,city_href]  \n",
    "            counter+=1\n",
    "print(final_df_cities_bs)\n",
    "end_bs = time.time()\n",
    "print('Processing Time: ',end_bs - start_bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c88bc6",
   "metadata": {},
   "source": [
    "## Step 3: Comparing Performance of Beautiful Soup vs Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "914a8bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beautiful Soup\n",
      "Time Taken:  26.27956199645996\n",
      "Total Requests to website:  20\n",
      "Selenium\n",
      "Time Taken:  92.0613260269165\n",
      "Total Requests to website:  1\n"
     ]
    }
   ],
   "source": [
    "print('Beautiful Soup')\n",
    "print('Time Taken: ',end_bs-start_bs)\n",
    "print('Total Requests to website: ', len(final_df_cities_bs))\n",
    "\n",
    "print('Selenium')\n",
    "print('Time Taken: ',end-start)\n",
    "print('Total Requests to website: ',1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ca96b",
   "metadata": {},
   "source": [
    "## Step 4: Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52a9974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the dataframe in to an excel file\n",
    "result=final_df_cities\n",
    "writer=pd.ExcelWriter('Cities_Summary.xlsx') \n",
    "result.to_excel(writer,'city summary')\n",
    "writer.save() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3246bc",
   "metadata": {},
   "source": [
    "# <a id=HomeLevel>2. Home Level - Data Collection </a> \n",
    "\n",
    "#### This section uses the BeautifulSoup package to scrape all home data 6 of the top most populated cities in the Bay Area\n",
    "#### Cupertino, Gilroy, Sunnyvale, Santa Clara, San Jose, Morgan Hill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914239a7",
   "metadata": {},
   "source": [
    "### Step 1: Iteration\n",
    "#### Loop through each of the pages in each city to extract all the house data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ad259",
   "metadata": {},
   "outputs": [],
   "source": [
    "with requests.Session() as s:\n",
    "    pages = np.arange(1, 3, 1)\n",
    "    Bed_Bath_Sqft_df = []\n",
    "    Price_df = []\n",
    "    Address_df = []\n",
    "    URL_df = []\n",
    "    Walk_Score_df = []\n",
    "    Transit_Score_df = []\n",
    "    Bike_Score_df = []\n",
    "    Places_Nearby_df =[]\n",
    "    Status = []\n",
    "    Property_Type = []\n",
    "    HOA = []\n",
    "    Sold_Year = []\n",
    "    Community = []\n",
    "    Lot_Size = []\n",
    "    Redfin_Est = []\n",
    "    Price_Per_Sqft = []\n",
    "    Buyers_Agent_Commision = []\n",
    "    Year_Built = []\n",
    "    Time_On_Redfin = []\n",
    "    Storm_Risk = []\n",
    "    Drought_Risk = []\n",
    "    Heat_Risk = []\n",
    "    Fire_Risk = []\n",
    "    domain_var = \"https://www.redfin.com/city/\"\n",
    "    property_type_var = \"filter/property-type=house+condo+townhouse+multifamily/\"\n",
    "    City_List=['4561/CA/Cupertino','7521/CA/Gilroy/','19457/CA/Sunnyvale/','19457/CA/Santa-Clara','17420/CA/San-Jose','12625/CA/Morgan-Hill']\n",
    "    property_status_var = ['include=sold-3yr/','status=active/']\n",
    "    \n",
    "    for city in City_List:  #Loop to read data from the above mentioned Bay Area cities\n",
    "        \n",
    "        for status_var in property_status_var:    #Loop to read data for Sold and Active properties\n",
    "            \n",
    "            actual_status = ''\n",
    "            if(status_var == 'include=sold-3yr/'):\n",
    "                actual_status = 'Sold'\n",
    "            elif(status_var == 'status=active/'):\n",
    "                actual_status = 'Active'\n",
    "                               \n",
    "            for page in pages:   #Loop to read multiple pages of the property data\n",
    "                \n",
    "                url = domain_var + city + property_type_var + status_var + 'page-'+str(page)\n",
    "                r = s.get(url, headers = {'User-Agent': 'Mozilla/5.0'})\n",
    "                soup = BS(r.content,'html.parser')    #main soup object to read the high level data of the properties\n",
    "                \n",
    "                my_table = soup.find_all(class_= ['HomeStatsV2'])\n",
    "                for tag in my_table:\n",
    "                    Bed_Bath_Sqft_df.append(tag.get_text())\n",
    "                my_table = soup.find_all(class_= ['homecardV2Price'])\n",
    "                for tag in my_table:\n",
    "                    Price_df.append(tag.get_text())\n",
    "                my_table = soup.find_all(class_= ['link-and-anchor'])\n",
    "                for tag in my_table:\n",
    "                    Address_df.append(tag.get_text())\n",
    "                my_url = soup.find_all('a',attrs = {'class':'slider-item'})\n",
    "                for urllist in my_url:\n",
    "                    URL_df.append('https://www.redfin.com/'+urllist.get('href'))\n",
    "                    Status.append(actual_status)\n",
    "\n",
    "#Initializing the dataframe and reading data into it\n",
    "df = pd.DataFrame( columns =['Bed Bath Sqft','Price','Address','URL','Walk Score','Transit Score','Bike Score','Places Nearby','Storm Risk','Drought Risk','Heat Risk','Fire Risk'])\n",
    "\n",
    "df['Bed Bath Sqft'] = pd.Series(Bed_Bath_Sqft_df)\n",
    "df['Address'] = pd.Series(Address_df)\n",
    "df['Price'] = pd.Series(Price_df)\n",
    "df['URL'] = pd.Series(URL_df)\n",
    "df['Status'] = pd.Series(Status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460d5d06",
   "metadata": {},
   "source": [
    "### Step 2: Append & Save \n",
    "#### Loop through each of the pages in each city to extract all the house data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa120353",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ind in df.index:    #Loop to read data from the individual properties fetched above\n",
    "    url =(df['URL'][ind])\n",
    "    \n",
    "    r = s.get(url, headers ={'User-Agent': 'Mozilla/5.0'})\n",
    "    \n",
    "    soup_house = BS(r.content,'html.parser')\n",
    "    \n",
    "#WalkScore    \n",
    "    try:\n",
    "        for tag1 in soup_house.find( class_ =[\"transport-icon-and-percentage walkscore\"] ).find( class_ =[\"percentage\"] ).find_all( class_ =[\"value fair\",\"value good\",\"value poor\"] ):\n",
    "            walk_score = tag1.get_text()\n",
    "            if (walk_score is None): \n",
    "                walk_score=0\n",
    "    except:\n",
    "        walk_score=0\n",
    "    Walk_Score_df.append(walk_score)\n",
    "    \n",
    "\n",
    "#TransitScore\n",
    "    try:\n",
    "        for tag1 in soup_house.find( class_ =[\"transport-icon-and-percentage transitscore\"] ).find( class_ =[\"percentage\"] ).find_all( class_ =[\"value fair\",\"value good\",\"value poor\"] ):\n",
    "            transit_score = tag1.get_text()\n",
    "            if (transit_score is None): \n",
    "                transit_score=0\n",
    "    except:\n",
    "        transit_score=0\n",
    "    Transit_Score_df.append(transit_score) \n",
    "       \n",
    "\n",
    "#BikeScore        \n",
    "    try:\n",
    "        for tag1 in soup_house.find( class_ =[\"transport-icon-and-percentage bikescore\"] ).find( class_ =[\"percentage\"] ).find_all( class_ =[\"value fair\",\"value good\",\"value poor\"] ):\n",
    "            bike_score = tag1.get_text()\n",
    "            if (bike_score is None): \n",
    "                bike_score=0\n",
    "    except:\n",
    "        bike_score=0\n",
    "    Bike_Score_df.append(bike_score)\n",
    "    \n",
    "    \n",
    "#PROPERTY TYPE\n",
    "    try:\n",
    "        actual_property_type_value = ''\n",
    "        for property_type_raw in soup_house.findAll('div', attrs = {'class':'keyDetail font-weight-roman font-size-base'}):\n",
    "            if(property_type_raw.span.text == 'Property Type'):\n",
    "                property_type_value_span = property_type_raw.find('span', attrs = {'class': 'content text-right'})\n",
    "                actual_property_type_value = property_type_value_span.text\n",
    "    except:\n",
    "        actual_property_type_value = \"None\"            \n",
    "\n",
    "    Property_Type.append(actual_property_type_value)\n",
    "    \n",
    "    \n",
    "#HOA\n",
    "    try:\n",
    "        actual_hoa_value = 0 \n",
    "        for hoa_raw in soup_house.findAll('div', attrs = {'class':'keyDetail font-weight-roman font-size-base'}):\n",
    "            if(hoa_raw.span.text == 'HOA Dues'):\n",
    "                hoa_raw_span = hoa_raw.find('span', attrs = {'class': 'content text-right'})\n",
    "                actual_hoa_value = hoa_raw_span.text.strip('$')\n",
    "    except:\n",
    "        actual_hoa_value = 0        \n",
    "\n",
    "    HOA.append(actual_hoa_value)\n",
    "    \n",
    "    \n",
    "#YEAR BUILT\n",
    "    try:\n",
    "        actual_year_built_value = 9999\n",
    "        for year_built_raw in soup_house.findAll('div', attrs = {'class':'keyDetail font-weight-roman font-size-base'}):\n",
    "            if(year_built_raw.span.text == 'Year Built'):\n",
    "                year_built_raw_span = year_built_raw.find('span', attrs = {'class': 'content text-right'})\n",
    "                actual_year_built_value = year_built_raw_span.text\n",
    "    except:\n",
    "        actual_year_built_value = 9999\n",
    "        \n",
    "    Year_Built.append(actual_year_built_value)\n",
    "    \n",
    "    \n",
    "#COMMUNITY\n",
    "    try:\n",
    "        actual_community_value = '' \n",
    "        for community_raw in soup_house.findAll('div', attrs = {'class':'keyDetail font-weight-roman font-size-base'}):\n",
    "            if(community_raw.span.text == 'Community'):\n",
    "                community_raw_span = community_raw.find('span', attrs = {'class': 'content text-right'})\n",
    "                actual_community_value = community_raw_span.text\n",
    "    except:\n",
    "        actual_community_value = \"None\"\n",
    "        \n",
    "    Community.append(actual_community_value)\n",
    "    \n",
    "    \n",
    "#LOT SIZE\n",
    "    try:\n",
    "        actual_lot_size_value = 0 \n",
    "        for lot_size_raw in soup_house.findAll('div', attrs = {'class':'keyDetail font-weight-roman font-size-base'}):\n",
    "            if(lot_size_raw.span.text == 'Lot Size'):\n",
    "                lot_size_span = lot_size_raw.find('span', attrs = {'class': 'content text-right'})\n",
    "                actual_lot_size_value = lot_size_span.text.strip(' Sq.Ft.').strip(',')\n",
    "    except:\n",
    "        actual_lot_size_value = 0\n",
    "        \n",
    "    Lot_Size.append(actual_lot_size_value)\n",
    "    \n",
    "    \n",
    "#TIME ON REDFIN\n",
    "    try:\n",
    "        actual_time_on_redfin_value = 0 \n",
    "        for time_on_redfin_raw in soup_house.findAll('div', attrs = {'class':'keyDetail font-weight-roman font-size-base'}):\n",
    "            if(time_on_redfin_raw.span.text == 'Time on Redfin'):\n",
    "                time_on_redfin_span = time_on_redfin_raw.find('span', attrs = {'class': 'content text-right'})\n",
    "                actual_time_on_redfin_value = time_on_redfin_span.text \n",
    "    except:\n",
    "        actual_time_on_redfin_value = 0\n",
    "        \n",
    "    Time_On_Redfin.append(actual_time_on_redfin_value)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "#REDFIN ESTIMATE\n",
    "    try:\n",
    "        actual_redfin_est_value = 0\n",
    "        for redfin_est_raw in soup_house.findAll('div', attrs = {'class':'keyDetail font-weight-roman font-size-base', 'data-rf-test-id':'key-detail-estimate'}):\n",
    "            redfin_est_value_span = redfin_est_raw.find('span', attrs = {'class': 'content text-right'})\n",
    "            actual_redfin_est_value = redfin_est_value_span.text.strip('$').strip(',')\n",
    "    except:\n",
    "        actual_redfin_est_value = 0\n",
    "        \n",
    "    Redfin_Est.append(actual_redfin_est_value)\n",
    "    \n",
    "    \n",
    "    \n",
    "#PRICE/SQ.FT.\n",
    "    try:\n",
    "        actual_price_per_sqft_value = 0\n",
    "        for price_per_sqft_raw in soup_house.findAll('div', attrs = {'class':'keyDetail font-weight-roman font-size-base'}):\n",
    "            if(price_per_sqft_raw.span.text == 'Price/Sq.Ft.'):\n",
    "                price_per_sqft_span = price_per_sqft_raw.find('span', attrs = {'class': 'content text-right'})\n",
    "                actual_price_per_sqft_value = price_per_sqft_span.text.strip('$').strip(',')\n",
    "    except:\n",
    "        actual_price_per_sqft_value = 0\n",
    "        \n",
    "    Price_Per_Sqft.append(actual_price_per_sqft_value)\n",
    "    \n",
    "    \n",
    "#BUYER'S AGENT COMMISSION\n",
    "    try:\n",
    "        actual_buyers_agent_commission_value = 0\n",
    "        for buyers_agent_commission_raw in soup_house.findAll('div', attrs = {'class':'keyDetail font-weight-roman font-size-base'}):\n",
    "                buyers_agent_commission_span = buyers_agent_commission_raw.find('span', attrs = {'class': 'content text-right'})\n",
    "                actual_buyers_agent_commission_value = buyers_agent_commission_span.text.strip('%')\n",
    "    except:\n",
    "        actual_buyers_agent_commission_value = 0\n",
    "            \n",
    "    Buyers_Agent_Commision.append(actual_buyers_agent_commission_value)\n",
    "    \n",
    "    \n",
    "#CLIMATE ATTRIBUTES   \n",
    "    try:\n",
    "        Climate_List = []\n",
    "        \n",
    "        for attr in soup_house.find_all('b', attrs = {'class':'riskScoreLevel'}):\n",
    "            Climate_List.append(attr.string)\n",
    "            \n",
    "    except:\n",
    "        Climate_List = [\"None\", \"None\", \"None\", \"None\"]\n",
    "   \n",
    "    \n",
    "    try:\n",
    "        for risk in Climate_List:\n",
    "            Storm_Risk.append(Climate_List[0])\n",
    "            Drought_Risk.append(Climate_List[1])\n",
    "            Heat_Risk.append(Climate_List[2])\n",
    "            Fire_Risk.append(Climate_List[3])\n",
    "    except:\n",
    "        Storm_Risk.append(\"None\")\n",
    "        Drought_Risk.append(\"None\")\n",
    "        Heat_Risk.append(\"None\")\n",
    "        Fire_Risk.append(\"None\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7645504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign data to the dataframe and display the content\n",
    "df['Walk Score'] = Walk_Score_df\n",
    "df['Transit Score'] = Transit_Score_df\n",
    "df['Bike Score'] = Bike_Score_df\n",
    "\n",
    "df['Property Type'] = pd.Series(Property_Type)\n",
    "df['Hoa Dues'] = pd.Series(HOA)\n",
    "df['Year Built'] =  pd.Series(Year_Built)\n",
    "df['Community'] =  pd.Series(Community)\n",
    "df['Lot Size'] =  pd.Series(Lot_Size)\n",
    "df['Time on Redfin'] = pd.Series(Time_On_Redfin)\n",
    "\n",
    "df['Redfin Estimate'] =  pd.Series(Redfin_Est)\n",
    "df['Price Per Sq.Ft.'] =  pd.Series(Price_Per_Sqft)\n",
    "df['Buyers Agent Commission'] =  pd.Series(Buyers_Agent_Commision)\n",
    "df['Storm Risk'] = pd.Series(Storm_Risk)\n",
    "df['Drought Risk'] = pd.Series(Drought_Risk)\n",
    "df['Heat Risk'] = pd.Series(Heat_Risk)\n",
    "df['Fire Risk'] = pd.Series(Fire_Risk)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece2507d",
   "metadata": {},
   "source": [
    "### Step 3: Save result in excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8aa521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the dataframe in to an excel file\n",
    "result=df\n",
    "writer=pd.ExcelWriter('Project_HomeData.xlsx') \n",
    "result.to_excel(writer,'homes')\n",
    "writer.save() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba867cc",
   "metadata": {},
   "source": [
    "# <a id=CityLevel>3. City Level - Data Collection </a> \n",
    "\n",
    "\n",
    "#### This section uses the BeautifulSoup package to scrape all home data 13 chosen cities based on population, popularity in the Bay Area\n",
    "\n",
    "#### Cupertino, Gilroy, Sunnyvale, Santa Clara, San Jose, Morgan Hill, Los Altos, Saratoga, Campbell, Los Gatos, Palo Alto, Milipitas, Mountain View"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7306ddc8",
   "metadata": {},
   "source": [
    "### Step 1: Iteration\n",
    "#### Loop through each of the pages in each city to extract all the house data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483c2ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Beautifulsoup \n",
    "\n",
    "req1 = Request('https://www.redfin.com/city/19457/CA/Sunnyvale/housing-market#trends', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "req2 = Request('https://www.redfin.com/city/17420/CA/San-Jose/housing-market#trends', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "req3 = Request('https://www.redfin.com/city/4561/CA/Cupertino/housing-market#trends', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "req4 = Request('https://www.redfin.com/city/12739/CA/Mountain-View/housing-market#trends', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "req5 = Request('https://www.redfin.com/city/12204/CA/Milpitas/housing-market#trends', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "req6 = Request('https://www.redfin.com/city/14325/CA/Palo-Alto/housing-market#trends', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "req7 = Request('https://www.redfin.com/city/17675/CA/Santa-Clara/housing-market#trends', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "req8 = Request('https://www.redfin.com/city/11234/CA/Los-Gatos/housing-market#trends', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "req9 = Request('https://www.redfin.com/city/11234/CA/Campbell/housing-market#trends', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "req10 = Request('https://www.redfin.com/city/7521/CA/Gilroy/housing-market#trends', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "req11 = Request('https://www.redfin.com/city/17960/CA/Saratoga/housing-market#trends', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "req12 = Request('https://www.redfin.com/city/12625/CA/Morgan-Hill/housing-market#trends', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "req13 = Request('https://www.redfin.com/city/11018/CA/Los-Altos/housing-market#trends', headers={'User-Agent': 'Mozilla/5.0'})\n",
    "listreq = [req1,req2,req3,req4,req5,req6,req7,req8,req9,req10,req11,req12,req13]\n",
    "\n",
    "stats= {\"Competitive_Score\":[],\"#of houses sold\":[],\"Home sold above list price\":[],\"School rating\":[]}\n",
    "competitative = []\n",
    "for r in listreq:\n",
    "    webpage = urlopen(r)\n",
    "    soup = BS(webpage,'html.parser')\n",
    "#competitative Score\n",
    "    for i in soup.findAll('div',attrs={'class':\"score most\"})[:1]:\n",
    "              c= i.get_text()  \n",
    "    competitative.append(c)\n",
    "    stats[\"Competitive_Score\"].append(c)\n",
    "    btn=soup.findAll(\"button\", {\"class\":\"ModeOption button-text\"})\n",
    "    values = []\n",
    "#Number of Houses sold\n",
    "    for i in btn:\n",
    "        x = i.findAll('div',{\"class\":\"tab\"})\n",
    "        for j in x:\n",
    "            y=j.find('div',{\"class\":\"value\"})\n",
    "            value = y.get_text()\n",
    "            values.append(value)\n",
    "    stats[\"#of houses sold\"].append(values[0])\n",
    "    stats[\"Home sold above list price\"].append(values[2])\n",
    "#School rating\n",
    "    risk = soup.find(\"div\", {\"class\":\"schools-content\"})\n",
    "    child = risk.findChildren(\"table\",{\"class\":\"basic-table-3\"},recursive= True)\n",
    "    ratings = []\n",
    "    for x in child:\n",
    "        for l in x.findAll('tr',{\"class\":\"schools-table-row\"}):\n",
    "            for line in l.findAll('td',{\"class\":\"rating-and-name-col\"}):\n",
    "                for y in line.findAll('div',{\"class\":\"gs-rating-col\"}):\n",
    "                    rating =y.find('span',{\"class\":\"rating-num\"}).get_text()\n",
    "                    ratings.append(int(rating))\n",
    "        stats[\"School rating\"].append(sum(ratings)/len(ratings))\n",
    "    \n",
    "#Merging into a dataframe\n",
    "df = pd.DataFrame(stats)\n",
    "df.index = ['Sunnyvale', 'San-Jose', 'Cupertino','Mountain-View','Milpitas','Palo-Alto','Santa Clara','Los Gatos','Campbell','Gilroy','Saratoga','Morgan-Hill',\n",
    "           'Los-Altos']\n",
    "#Writing to an excel\n",
    "writer=pd.ExcelWriter('Cities statistics.xlsx')\n",
    "df.to_excel(writer,'Cities statistics',index= True)\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1154565",
   "metadata": {},
   "source": [
    "## Step 2: Selenium (City Level)\n",
    "\n",
    "### Due to errros in using Selenium we have reverted to using Redfin's API consisting of all data points and readily available directly on their website: https://www.redfin.com/news/data-center/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c5c64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
